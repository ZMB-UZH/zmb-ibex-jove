{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f99981cb-ebe3-49c7-9e58-84e82c198943",
   "metadata": {},
   "source": [
    "To execute a cell with code, select it & press Shift+Enter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a623d-fac3-45eb-949b-2c964357c20c",
   "metadata": {},
   "source": [
    "# Registering stitched data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77396cbe-bd8e-4b38-b21a-cdfe336170d5",
   "metadata": {},
   "source": [
    "## Define file-paths:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ad6d2-5e93-4bb3-8e92-fb629ee8a3b0",
   "metadata": {},
   "source": [
    "Your files should be saved with the following structure and `<name>` and `<channel>` should be the actual name and channel: \n",
    "('*' can be any characters)\n",
    "```\n",
    "base_dir\n",
    "├───round1\n",
    "│   ├───*A1*\n",
    "│   │   └───<name>_<channel1>.ome.tif\n",
    "│   │   ├───<name>_<channel2>.ome.tif\n",
    "|   |   .\n",
    "|   |   .\n",
    "├───round2\n",
    "│   ├───*A1*\n",
    "│   │   └───<name>_<channel1>.ome.tif\n",
    "|   |   .\n",
    "|   |   .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1954f92e-929b-4422-b2be-62a945ec8650",
   "metadata": {},
   "source": [
    "In the cell below, change the following file-paths:\n",
    "* `reference_channel`: the reference channel, which is used for registration (ususally 'DAPI')\n",
    "* `reference_round`: the reference round to which everything is aligned\n",
    "* `base_dir`: the directory where all rounds are in\n",
    "* `save_dir`: the directory where the registered images will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f02ac9-e3fd-4741-a5e0-1d401997ad8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INPUT REQUIRED\n",
    "reference_channel = \"DAPI\"\n",
    "reference_round = \"1\"\n",
    "base_dir = r\"Z:\\zmbstaff\\9780\\Processed_Data\\MD_1\\stitched\"\n",
    "save_dir = r\"Z:\\zmbstaff\\9780\\Processed_Data\\MD_1\\registered\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2779dff-930f-47eb-9b2c-a61b10ce04cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import modules and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554fd07-f589-4af4-92cd-d384105ef22e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import napari\n",
    "import numpy as np\n",
    "import ome_types\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "from skimage.measure import block_reduce\n",
    "from skimage.registration import phase_cross_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f25dc8-8f0c-484c-a8c1-63670c17b9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def register(img1, img2, upsample_factor):\n",
    "    min_z, min_y, min_x = np.array([img1.shape, img2.shape]).min(axis=0)\n",
    "    shift, error, phasediff = phase_cross_correlation(\n",
    "        img1[:min_z, :min_y, :min_x],\n",
    "        img2[:min_z, :min_y, :min_x],\n",
    "        disambiguate=False,\n",
    "        upsample_factor=upsample_factor,\n",
    "    )\n",
    "    return shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e00d1-fe77-486d-b4ec-be11e6ad1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_reduce_seq(data, block_size, seq_size=256):\n",
    "    fragments_ds = []\n",
    "    for i in np.arange(0, data.shape[-1], (block_size[-1] * seq_size)):\n",
    "        fragment = data[\n",
    "            :, :, i : np.min([i + (block_size[-1] * seq_size), data.shape[-1]])\n",
    "        ]\n",
    "        fragment_ds = block_reduce(\n",
    "            fragment,\n",
    "            block_size=block_size,\n",
    "            func=np.mean,\n",
    "            func_kwargs={\"dtype\": data.dtype},\n",
    "        )\n",
    "        fragments_ds.append(fragment_ds)\n",
    "    return np.concatenate(fragments_ds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e91351a-7a21-4707-be7e-9ccd122fbdd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for registration, the images will be downsampled with these factors (can be adjusted, if needed)\n",
    "downsample_factors = np.array((2, 6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3163c488-d2df-4782-be8f-dd8fe339e7da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Locate files and generate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969c9af-2342-4e3e-a1b7-cfb5b21e9731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load files into dataframe\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "fns = glob.glob(os.path.join(base_dir, \"round*\", \"*\", \"*.ome.tif\"))\n",
    "pattern = r\".*[\\/\\\\]round(?P<round>\\d+)[\\/\\\\](?P<well>[A-Z]\\d+)[\\/\\\\](?P<name>.*)_(?P<channel>.*).ome.tif\"\n",
    "files = []\n",
    "for fn in fns:\n",
    "    match = re.fullmatch(pattern, fn)\n",
    "    row = match.groupdict()\n",
    "    row[\"path\"] = fn\n",
    "    files.append(row)\n",
    "files = pd.DataFrame(files)\n",
    "wells = files[\"well\"].unique()\n",
    "rounds = files[\"round\"].unique()\n",
    "\n",
    "# add some metadata to dataframe\n",
    "for index, file in files.iterrows():\n",
    "    ome_dict = ome_types.to_dict(ome_types.from_tiff(file.path))\n",
    "    (dx, dy, dz) = [\n",
    "        ome_dict[\"images\"][0][\"pixels\"][key]\n",
    "        for key in [\"physical_size_x\", \"physical_size_y\", \"physical_size_z\"]\n",
    "    ]\n",
    "    files.loc[index, [\"dx\", \"dy\", \"dz\"]] = (dx, dy, dz)\n",
    "    (dim_x, dim_y, dim_z) = [\n",
    "        ome_dict[\"images\"][0][\"pixels\"][key] for key in [\"size_x\", \"size_y\", \"size_z\"]\n",
    "    ]\n",
    "    files.loc[index, [\"dim_x\", \"dim_y\", \"dim_z\"]] = (dim_x, dim_y, dim_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935fda8-c28c-48e9-90d9-8bde86275987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab6da09-c7be-410b-a808-e6a11a3f812f",
   "metadata": {},
   "source": [
    "## process all wells:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32182ada-8207-4948-9958-9d11419707a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### load and save channels as individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87abaab8-9b03-4abb-ad52-24af9ac330b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for well in wells:\n",
    "    well_files = files.query(\"well==@well\")\n",
    "    for name in well_files[\"name\"].unique():\n",
    "        print(\"\\nPROCESSING WELL \" + well + \", \" + name)\n",
    "\n",
    "        name_files = well_files.query(\"name==@name\")\n",
    "        reg_files = name_files.query(\"channel==@reference_channel\")\n",
    "\n",
    "        print(\"\\nloading and registering reference channel...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        fix_file = reg_files.query(\"round==@reference_round\").iloc[0]\n",
    "        fix_img = tifffile.imread(fix_file[\"path\"])\n",
    "        fix_img_ds = block_reduce_seq(\n",
    "            fix_img, block_size=tuple(downsample_factors), seq_size=256\n",
    "        )\n",
    "        files.loc[fix_file.name, [\"shift_x\", \"shift_y\", \"shift_z\"]] = 0\n",
    "        for index, file in reg_files.query(\"round!=@reference_round\").iterrows():\n",
    "            mov_img = tifffile.imread(file[\"path\"])\n",
    "            mov_img_ds = block_reduce_seq(\n",
    "                mov_img, block_size=tuple(downsample_factors), seq_size=256\n",
    "            )\n",
    "            shift_px_ds = register(fix_img_ds, mov_img_ds, np.max(downsample_factors))\n",
    "            shift_px = np.round(shift_px_ds * downsample_factors).astype(int)\n",
    "            files.loc[index, [\"shift_z\", \"shift_y\", \"shift_x\"]] = shift_px\n",
    "        for index, file in name_files.iterrows():\n",
    "            round = file[\"round\"]\n",
    "            shift_px = files.query(\n",
    "                \"well==@well and channel==@reference_channel and round==@round\"\n",
    "            ).iloc[0][[\"shift_z\", \"shift_y\", \"shift_x\"]]\n",
    "            files.loc[index, [\"shift_z\", \"shift_y\", \"shift_x\"]] = shift_px\n",
    "        shifts = files.query(\"well==@well\")[[\"shift_z\", \"shift_y\", \"shift_x\"]].to_numpy(\n",
    "            dtype=int\n",
    "        )\n",
    "        shifts = shifts - shifts.min(axis=0)\n",
    "        files.loc[\n",
    "            files.query(\"well==@well\").index, [\"shift_z\", \"shift_y\", \"shift_x\"]\n",
    "        ] = shifts\n",
    "        dims = files.query(\"well==@well\")[[\"dim_z\", \"dim_y\", \"dim_x\"]].to_numpy(\n",
    "            dtype=int\n",
    "        )\n",
    "        nz, ny, nx = np.max(shifts + dims, axis=0)\n",
    "\n",
    "        print(f\"took {(time.time() - start_time):.1f}s\")\n",
    "\n",
    "        print(\"\\nloading and aligning all channels...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        for index, _ in name_files.iterrows():\n",
    "            file = files.loc[index]\n",
    "            round = file[\"round\"]\n",
    "            channel = file[\"channel\"]\n",
    "            channel_name = f\"round{round}_{channel}\"\n",
    "            print(f\"Processing {channel_name}\")\n",
    "            print(\"Loading...\")\n",
    "            img = tifffile.imread(file[\"path\"])\n",
    "            slc_z = slice(int(file[\"shift_z\"]), int(file[\"shift_z\"] + file[\"dim_z\"]))\n",
    "            slc_y = slice(int(file[\"shift_y\"]), int(file[\"shift_y\"] + file[\"dim_y\"]))\n",
    "            slc_x = slice(int(file[\"shift_x\"]), int(file[\"shift_x\"] + file[\"dim_x\"]))\n",
    "            img_reg = np.zeros((nz, ny, nx), dtype=img.dtype)\n",
    "            img_reg[slc_z, slc_y, slc_x] = img\n",
    "            os.makedirs(os.path.join(save_dir, name + \"_\" + well), exist_ok=True)\n",
    "            print(\"Saving...\")\n",
    "            with tifffile.TiffWriter(\n",
    "                os.path.join(save_dir, name + \"_\" + well, channel_name + \".ome.tif\"),\n",
    "                bigtiff=True,\n",
    "            ) as tif:\n",
    "                metadata = {\n",
    "                    \"axes\": \"ZYX\",\n",
    "                    \"PhysicalSizeX\": dx,\n",
    "                    \"PhysicalSizeXUnit\": \"µm\",\n",
    "                    \"PhysicalSizeY\": dy,\n",
    "                    \"PhysicalSizeYUnit\": \"µm\",\n",
    "                    \"PhysicalSizeZ\": dz,\n",
    "                    \"PhysicalSizeZUnit\": \"µm\",\n",
    "                    \"Channel\": {\"Name\": channel_name},\n",
    "                }\n",
    "                options = dict(\n",
    "                    photometric=\"minisblack\",\n",
    "                )\n",
    "                tif.write(img_reg, metadata=metadata, **options)\n",
    "\n",
    "        print(f\"took {(time.time() - start_time):.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2bc1b-a188-4199-aeaa-c17600e4990d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0002eedf-cb0d-441c-b809-9c5094ba9d58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### load and save all channels together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28714ab-c292-442a-8654-30b62bed5ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for well in wells:\n",
    "    well_files = files.query(\"well==@well\")\n",
    "    for name in well_files[\"name\"].unique():\n",
    "        print(\"\\nPROCESSING WELL \" + well + \", \" + name)\n",
    "\n",
    "        name_files = well_files.query(\"name==@name\")\n",
    "        reg_files = name_files.query(\"channel==@reference_channel\")\n",
    "\n",
    "        print(\"\\nloading and registering reference channel...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        fix_file = reg_files.query(\"round==@reference_round\").iloc[0]\n",
    "        fix_img = tifffile.imread(fix_file[\"path\"])\n",
    "        fix_img_ds = block_reduce_seq(\n",
    "            fix_img, block_size=tuple(downsample_factors), seq_size=256\n",
    "        )\n",
    "        files.loc[fix_file.name, [\"shift_x\", \"shift_y\", \"shift_z\"]] = 0\n",
    "        for index, file in reg_files.query(\"round!=@reference_round\").iterrows():\n",
    "            mov_img = tifffile.imread(file[\"path\"])\n",
    "            mov_img_ds = block_reduce_seq(\n",
    "                mov_img, block_size=tuple(downsample_factors), seq_size=256\n",
    "            )\n",
    "            shift_px_ds = register(fix_img_ds, mov_img_ds, np.max(downsample_factors))\n",
    "            shift_px = np.round(shift_px_ds * downsample_factors).astype(int)\n",
    "            files.loc[index, [\"shift_z\", \"shift_y\", \"shift_x\"]] = shift_px\n",
    "        for index, file in name_files.iterrows():\n",
    "            round = file[\"round\"]\n",
    "            shift_px = files.query(\n",
    "                \"well==@well and channel==@reference_channel and round==@round\"\n",
    "            ).iloc[0][[\"shift_z\", \"shift_y\", \"shift_x\"]]\n",
    "            files.loc[index, [\"shift_z\", \"shift_y\", \"shift_x\"]] = shift_px\n",
    "        shifts = files.query(\"well==@well\")[[\"shift_z\", \"shift_y\", \"shift_x\"]].to_numpy(\n",
    "            dtype=int\n",
    "        )\n",
    "        shifts = shifts - shifts.min(axis=0)\n",
    "        files.loc[\n",
    "            files.query(\"well==@well\").index, [\"shift_z\", \"shift_y\", \"shift_x\"]\n",
    "        ] = shifts\n",
    "        dims = files.query(\"well==@well\")[[\"dim_z\", \"dim_y\", \"dim_x\"]].to_numpy(\n",
    "            dtype=int\n",
    "        )\n",
    "        nz, ny, nx = np.max(shifts + dims, axis=0)\n",
    "\n",
    "        print(f\"took {(time.time() - start_time):.1f}s\")\n",
    "\n",
    "        print(\"\\nloading and aligning all channels...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        channel_names = []\n",
    "        imgs_reg = np.zeros((len(name_files), nz, ny, nx), dtype=fix_img.dtype)\n",
    "        for n, (index, _) in enumerate(name_files.iterrows()):\n",
    "            file = files.loc[index]\n",
    "            round = file[\"round\"]\n",
    "            channel = file[\"channel\"]\n",
    "            channel_name = f\"round{round}_{channel}\"\n",
    "            channel_names.append(channel_name)\n",
    "            print(f\"Loading {channel_name}\")\n",
    "            img = tifffile.imread(file[\"path\"])\n",
    "            slc_z = slice(int(file[\"shift_z\"]), int(file[\"shift_z\"] + file[\"dim_z\"]))\n",
    "            slc_y = slice(int(file[\"shift_y\"]), int(file[\"shift_y\"] + file[\"dim_y\"]))\n",
    "            slc_x = slice(int(file[\"shift_x\"]), int(file[\"shift_x\"] + file[\"dim_x\"]))\n",
    "            imgs_reg[n, slc_z, slc_y, slc_x] = img\n",
    "\n",
    "        print(f\"took {(time.time() - start_time):.1f}s\")\n",
    "\n",
    "        print(\"\\nsaving data...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        subresolutions = 2\n",
    "        with tifffile.TiffWriter(\n",
    "            os.path.join(save_dir, name + \"_\" + well + \".ome.tif\"), bigtiff=True\n",
    "        ) as tif:\n",
    "            metadata = {\n",
    "                \"axes\": \"CZYX\",\n",
    "                \"PhysicalSizeX\": dx,\n",
    "                \"PhysicalSizeXUnit\": \"µm\",\n",
    "                \"PhysicalSizeY\": dy,\n",
    "                \"PhysicalSizeYUnit\": \"µm\",\n",
    "                \"PhysicalSizeZ\": dz,\n",
    "                \"PhysicalSizeZUnit\": \"µm\",\n",
    "                \"Channel\": {\"Name\": channel_names},\n",
    "            }\n",
    "            options = dict(\n",
    "                photometric=\"minisblack\",\n",
    "                tile=(128, 128),\n",
    "                resolutionunit=\"CENTIMETER\",\n",
    "                maxworkers=32,\n",
    "            )\n",
    "            tif.write(\n",
    "                imgs_reg,\n",
    "                subifds=subresolutions,\n",
    "                resolution=(1e4 / dy, 1e4 / dx),\n",
    "                metadata=metadata,\n",
    "                **options,\n",
    "            )\n",
    "            # write pyramid levels to the two subifds\n",
    "            # TODO: in production use resampling to generate sub-resolution images\n",
    "            for level in range(subresolutions):\n",
    "                mag = 2 ** (level + 1)\n",
    "                tif.write(\n",
    "                    imgs_reg[..., ::mag, ::mag],\n",
    "                    subfiletype=1,\n",
    "                    resolution=(1e4 / mag / dy, 1e4 / mag / dx),\n",
    "                    **options,\n",
    "                )\n",
    "\n",
    "        print(f\"took {(time.time() - start_time):.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85886f00-af85-4621-9f44-2f48c1afe882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28ecef15-2be7-48ce-8feb-114fb53e858b",
   "metadata": {},
   "source": [
    "## process wells individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4082fc1e-837f-49b1-8054-f1abdd35805d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INPUT REQUIRED\n",
    "well = \"A1\"\n",
    "name = \"stitched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21accec7-927a-4ff0-b050-6c038244a0ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "well_files = files.query(\"well==@well\")\n",
    "name_files = well_files.query(\"name==@name\")\n",
    "reg_files = name_files.query(\"channel==@reference_channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef06f55-2203-41a8-b7a1-760aa235ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fix_file = reg_files.query(\"round==@reference_round\").iloc[0]\n",
    "fix_img = tifffile.imread(fix_file[\"path\"])\n",
    "fix_img_ds = block_reduce_seq(\n",
    "    fix_img, block_size=tuple(downsample_factors), seq_size=256\n",
    ")\n",
    "files.loc[fix_file.name, [\"shift_x\", \"shift_y\", \"shift_z\"]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e7271b-802c-4522-b157-a2ec2f762ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for index, file in reg_files.query(\"round!=@reference_round\").iterrows():\n",
    "    mov_img = tifffile.imread(file[\"path\"])\n",
    "    mov_img_ds = block_reduce_seq(\n",
    "        mov_img, block_size=tuple(downsample_factors), seq_size=256\n",
    "    )\n",
    "    shift_px_ds = register(fix_img_ds, mov_img_ds, np.max(downsample_factors))\n",
    "    shift_px = np.round(shift_px_ds * downsample_factors).astype(int)\n",
    "    files.loc[index, [\"shift_z\", \"shift_y\", \"shift_x\"]] = shift_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca44901-871a-42be-87c7-793ff12c5a23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, file in name_files.iterrows():\n",
    "    round = file[\"round\"]\n",
    "    shift_px = files.query(\n",
    "        \"well==@well and channel==@reference_channel and round==@round\"\n",
    "    ).iloc[0][[\"shift_z\", \"shift_y\", \"shift_x\"]]\n",
    "    files.loc[index, [\"shift_z\", \"shift_y\", \"shift_x\"]] = shift_px\n",
    "shifts = files.query(\"well==@well\")[[\"shift_z\", \"shift_y\", \"shift_x\"]].to_numpy(\n",
    "    dtype=int\n",
    ")\n",
    "shifts = shifts - shifts.min(axis=0)\n",
    "files.loc[files.query(\"well==@well\").index, [\"shift_z\", \"shift_y\", \"shift_x\"]] = shifts\n",
    "dims = files.query(\"well==@well\")[[\"dim_z\", \"dim_y\", \"dim_x\"]].to_numpy(dtype=int)\n",
    "nz, ny, nx = np.max(shifts + dims, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea9d53f-374b-4f10-8b47-dbfb4ecc0243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6dd77-cfe1-4c3b-812d-b8d19d25b377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c90a5651-274c-4407-a4b9-98b393c3212b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### load and save channels as individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513e78b-97c3-4904-a09e-a14fb518637d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for index, _ in name_files.iterrows():\n",
    "    file = files.loc[index]\n",
    "    round = file[\"round\"]\n",
    "    channel = file[\"channel\"]\n",
    "    channel_name = f\"round{round}_{channel}\"\n",
    "    print(f\"Processing {channel_name}\")\n",
    "    print(\"Loading...\")\n",
    "    img = tifffile.imread(file[\"path\"])\n",
    "    slc_z = slice(int(file[\"shift_z\"]), int(file[\"shift_z\"] + file[\"dim_z\"]))\n",
    "    slc_y = slice(int(file[\"shift_y\"]), int(file[\"shift_y\"] + file[\"dim_y\"]))\n",
    "    slc_x = slice(int(file[\"shift_x\"]), int(file[\"shift_x\"] + file[\"dim_x\"]))\n",
    "    img_reg = np.zeros((nz, ny, nx), dtype=img.dtype)\n",
    "    img_reg[slc_z, slc_y, slc_x] = img\n",
    "    os.makedirs(os.path.join(save_dir, name + \"_\" + well), exist_ok=True)\n",
    "    print(\"Saving...\")\n",
    "    with tifffile.TiffWriter(\n",
    "        os.path.join(save_dir, name + \"_\" + well, channel_name + \".ome.tif\"),\n",
    "        bigtiff=True,\n",
    "    ) as tif:\n",
    "        metadata = {\n",
    "            \"axes\": \"ZYX\",\n",
    "            \"PhysicalSizeX\": dx,\n",
    "            \"PhysicalSizeXUnit\": \"µm\",\n",
    "            \"PhysicalSizeY\": dy,\n",
    "            \"PhysicalSizeYUnit\": \"µm\",\n",
    "            \"PhysicalSizeZ\": dz,\n",
    "            \"PhysicalSizeZUnit\": \"µm\",\n",
    "            \"Channel\": {\"Name\": channel_name},\n",
    "        }\n",
    "        options = dict(\n",
    "            photometric=\"minisblack\",\n",
    "        )\n",
    "        tif.write(img_reg, metadata=metadata, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58196c0-5418-4123-b817-14fff6d24918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b129b4b5-8930-4c69-ad36-c27c7dbeecda",
   "metadata": {
    "tags": []
   },
   "source": [
    "### load and save all channels together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a62d48-554a-4332-b73f-595a044385b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "channel_names = []\n",
    "imgs_reg = np.zeros((len(name_files), nz, ny, nx), dtype=fix_img.dtype)\n",
    "for n, (index, _) in enumerate(name_files.iterrows()):\n",
    "    file = files.loc[index]\n",
    "    round = file[\"round\"]\n",
    "    channel = file[\"channel\"]\n",
    "    channel_name = f\"round{round}_{channel}\"\n",
    "    channel_names.append(channel_name)\n",
    "    print(f\"Loading {channel_name}\")\n",
    "    img = tifffile.imread(file[\"path\"])\n",
    "    slc_z = slice(int(file[\"shift_z\"]), int(file[\"shift_z\"] + file[\"dim_z\"]))\n",
    "    slc_y = slice(int(file[\"shift_y\"]), int(file[\"shift_y\"] + file[\"dim_y\"]))\n",
    "    slc_x = slice(int(file[\"shift_x\"]), int(file[\"shift_x\"] + file[\"dim_x\"]))\n",
    "    imgs_reg[n, slc_z, slc_y, slc_x] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ec2bc-9444-473b-bfa4-70299938b4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(\n",
    "    imgs_reg,\n",
    "    blending=\"additive\",\n",
    "    channel_axis=0,\n",
    "    name=channel_names,\n",
    "    contrast_limits=(0, 2000),\n",
    "    scale=(dz, dy, dx),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049cadab-8f0c-4de9-939a-15beed02cba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "subresolutions = 2\n",
    "with tifffile.TiffWriter(\n",
    "    os.path.join(save_dir, name + \"_\" + well + \".ome.tif\"), bigtiff=True\n",
    ") as tif:\n",
    "    metadata = {\n",
    "        \"axes\": \"CZYX\",\n",
    "        \"PhysicalSizeX\": dx,\n",
    "        \"PhysicalSizeXUnit\": \"µm\",\n",
    "        \"PhysicalSizeY\": dy,\n",
    "        \"PhysicalSizeYUnit\": \"µm\",\n",
    "        \"PhysicalSizeZ\": dz,\n",
    "        \"PhysicalSizeZUnit\": \"µm\",\n",
    "        \"Channel\": {\"Name\": channel_names},\n",
    "    }\n",
    "    options = dict(\n",
    "        photometric=\"minisblack\",\n",
    "        tile=(128, 128),\n",
    "        resolutionunit=\"CENTIMETER\",\n",
    "        maxworkers=32,\n",
    "    )\n",
    "    tif.write(\n",
    "        imgs_reg,\n",
    "        subifds=subresolutions,\n",
    "        resolution=(1e4 / dy, 1e4 / dx),\n",
    "        metadata=metadata,\n",
    "        **options\n",
    "    )\n",
    "    # write pyramid levels to the two subifds\n",
    "    # TODO: in production use resampling to generate sub-resolution images\n",
    "    for level in range(subresolutions):\n",
    "        mag = 2 ** (level + 1)\n",
    "        tif.write(\n",
    "            imgs_reg[..., ::mag, ::mag],\n",
    "            subfiletype=1,\n",
    "            resolution=(1e4 / mag / dy, 1e4 / mag / dx),\n",
    "            **options\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567208be-e012-43e7-9075-f58c05af32bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d9967-9676-4b73-8485-fff1f2647676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a9a06-bfa3-4848-8ec2-e3673d8d943c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0692f54-d25f-43ef-8a55-be859e32336e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:zmb_hcs]",
   "language": "python",
   "name": "conda-env-zmb_hcs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
